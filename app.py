import streamlit as st
import os
import re
import json
import pandas as pd
import numpy as np
from collections import Counter, defaultdict
from typing import List, Dict, Tuple, Any, Set
from io import BytesIO
from datetime import date, datetime, timedelta
from groq import Groq

# ============================================================
# ğŸ¯ Ultimate Brand Intelligence Platform with KOL Monitoring
# Campaign tracking, risk assessment, and automated reporting
# ============================================================

# Optional dependencies
try:
    import plotly.express as px
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False

try:
    from wordcloud import WordCloud
    import matplotlib.pyplot as plt
    import matplotlib
    matplotlib.use('Agg')
    WORDCLOUD_AVAILABLE = True
except ImportError:
    WORDCLOUD_AVAILABLE = False

try:
    import jieba
    import jieba.analyse
    JIEBA_AVAILABLE = True
except ImportError:
    JIEBA_AVAILABLE = False

# ============================================================
# ğŸ” SECURE API KEY MANAGEMENT
# ============================================================

def get_groq_api_key() -> str:
    """Secure API key retrieval"""
    try:
        api_key = st.secrets.get("GROQ_API_KEY", "").strip()
        if api_key:
            return api_key
    except Exception:
        pass
    
    api_key = os.getenv("GROQ_API_KEY", "").strip()
    if api_key:
        return api_key
    
    return ""

def initialize_groq_client():
    """Initialize Groq client"""
    api_key = get_groq_api_key()
    
    if not api_key:
        st.sidebar.error("âš ï¸ Missing GROQ API KEY")
        st.sidebar.markdown("""
        **è®¾ç½® API Key:**
        
        **æ–¹æ³•1: Streamlit Secrets (æ¨è)**
        åˆ›å»º `~/.streamlit/secrets.toml`:
        ```toml
        GROQ_API_KEY = "your-key"
        ```
        
        **æ–¹æ³•2: ç¯å¢ƒå˜é‡**
        ```bash
        export GROQ_API_KEY="your-key"
        ```
        """)
        
        temp_key = st.sidebar.text_input("ä¸´æ—¶è¾“å…¥ API Key", type="password")
        if temp_key:
            api_key = temp_key
        else:
            st.stop()
    
    try:
        client = Groq(api_key=api_key, timeout=30.0, max_retries=3)
        return client
    except Exception as e:
        st.error(f"âŒ APIåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.stop()

client = initialize_groq_client()

# ============================================================
# ğŸ“Š ENHANCED CONFIGURATION
# ============================================================

# Comprehensive stopwords
CHINESE_STOPWORDS = {
    # é€šç”¨åœç”¨è¯
    "çš„", "äº†", "æ˜¯", "åœ¨", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸ª",
    "ä¸Š", "ä¹Ÿ", "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½",
    "è‡ªå·±", "è¿™", "é‚£", "é‡Œ", "æ¥", "ä¸º", "ä½†", "è€Œ", "ä¸", "æˆ–", "å•Š", "å‘€", "å—",
    "å‘¢", "å§", "å“¦", "å“ˆ", "å—¯", "å”‰", "å“", "å•¦", "ä¹ˆ", "å˜›", "å‘—", "å¾—",
    
    # æ— æ„ä¹‰é«˜é¢‘è¯
    "çœŸçš„", "æ„Ÿè§‰", "è§‰å¾—", "è¿˜æ˜¯", "ç„¶å", "æ‰€ä»¥", "å› ä¸º", "å¦‚æœ", "è¿™ä¸ª", "é‚£ä¸ª",
    "ä»€ä¹ˆ", "æ€ä¹ˆ", "éå¸¸", "æ¯”è¾ƒ", "å¯èƒ½", "åº”è¯¥", "è‚¯å®š", "ä¸€å®š", "ç»å¯¹", "çœŸæ˜¯",
    "ç¡®å®", "ç®€ç›´", "å®Œå…¨", "ååˆ†", "ç‰¹åˆ«", "å°¤å…¶", "æ€»ä¹‹", "åæ­£", "å…¶å®", "æœ¬æ¥",
    "å·²ç»", "è¿˜æœ‰", "è€Œä¸”", "ä¸è¿‡", "åªæ˜¯", "å¯æ˜¯", "ä½†æ˜¯", "è™½ç„¶", "å°½ç®¡",
    
    # å“ç‰Œç›¸å…³ï¼ˆåŠ¨æ€æ·»åŠ ï¼‰
    "å“ç‰Œ", "ç‰Œå­", "äº§å“", "ä¸œè¥¿", "è¿™æ¬¾", "é‚£æ¬¾", "è¿™ä¸ªç‰Œå­", "é‚£ä¸ªç‰Œå­",
    "è¿™å®¶", "é‚£å®¶", "å•†å®¶", "åº—å®¶",
    
    # ç”µå•†å¹³å°
    "æ——èˆ°åº—", "å®˜æ–¹", "åº—é“º", "å–å®¶", "ä¹°å®¶", "å®¢æœ", "è´­ä¹°", "ä¸‹å•", "æ”¶è´§",
    "åŒ…é‚®", "å¿«é€’", "ç‰©æµ", "å‘è´§", "åˆ°è´§", "ç­¾æ”¶",
    
    # å°çº¢ä¹¦ç‰¹è‰²è¯
    "å§å¦¹", "å®å®", "é›†ç¾", "å°çº¢ä¹¦", "ç¬”è®°", "ç§è‰", "æ‹”è‰", "å…¥å‘", "å‰æ‰‹",
    "å®‰åˆ©", "åˆ†äº«", "æ¨è", "æµ‹è¯„", "å¼€ç®±", "æ™’å•",
}

ENGLISH_STOPWORDS = {
    "the", "is", "are", "was", "were", "be", "been", "being", "a", "an", "and",
    "or", "but", "in", "on", "at", "to", "for", "of", "with", "by", "from", "as",
    "it", "this", "that", "these", "those", "i", "you", "he", "she", "we", "they",
    "my", "your", "his", "her", "our", "their", "what", "which", "who", "when",
    "where", "why", "how", "very", "really", "just", "so", "too", "more", "most"
}

# Enhanced sentiment terms
POSITIVE_TERMS = [
    # äº§å“ä½“éªŒ
    "å¥½", "æ£’", "å–œæ¬¢", "çˆ±", "æ¨è", "å€¼å¾—", "æ»¡æ„", "å®Œç¾", "èµ", "ä¼˜ç§€", "ä¸é”™",
    "å¥½ç”¨", "å®ç”¨", "èˆ’æœ", "æ¸©å’Œ", "æŸ”æ»‘", "æ˜¾ç™½", "æŒä¹…", "æ»‹æ¶¦", "ä¿æ¹¿", "æ¸…çˆ½",
    "è½»è–„", "æœå¸–", "è‡ªç„¶", "æ˜¾è‰²", "æ­£", "é¡ºæ»‘", "ç»†è…»", "ä¸æ»‘", "æ°´æ¶¦", "å«©",
    "èˆ’é€‚", "åˆé€‚", "é€‚åˆ", "åŒ¹é…", "è´´åˆ", "ä¸Šå¦†", "å¦†æ„Ÿ", "è´¨æ„Ÿ", "é«˜çº§æ„Ÿ",
    
    # ä»·å€¼æ„ŸçŸ¥
    "åˆ’ç®—", "è¶…å€¼", "æƒŠå–œ", "ç‰©è¶…æ‰€å€¼", "æ€§ä»·æ¯”é«˜", "å®æƒ ", "ä¾¿å®œ", "ä¼˜æƒ ", "æŠ˜æ‰£",
    "ç™½èœä»·", "è‰¯å¿ƒ", "äº²æ°‘", "åˆç†",
    
    # å¤–è§‚åŒ…è£…
    "é«˜çº§", "ç²¾è‡´", "æ¼‚äº®", "ç¾", "å¥½çœ‹", "é¢œå€¼é«˜", "å¤§æ°”", "æ—¶å°š", "å¥¢å", "æ¡£æ¬¡",
    "è´¨æ„Ÿ", "æœ‰è´¨æ„Ÿ", "ä¸Šæ¡£æ¬¡", "è®²ç©¶", "ç²¾ç¾", "é›…è‡´",
    
    # æœåŠ¡ç‰©æµ
    "å¿«", "åŠæ—¶", "è¿…é€Ÿ", "çƒ­æƒ…", "è€å¿ƒ", "ä¸“ä¸š", "è´´å¿ƒ", "å‘¨åˆ°", "æ»¡åˆ†",
    
    # è‹±æ–‡
    "good", "great", "love", "excellent", "perfect", "amazing", "best", "fantastic",
    "recommend", "worth", "satisfied", "quality", "premium", "smooth", "nice"
]

NEGATIVE_TERMS = [
    # äº§å“é—®é¢˜
    "å·®", "ä¸å¥½", "å¤±æœ›", "åæ‚”", "é¿é›·", "ç¿»è½¦", "å‘", "åƒåœ¾", "éš¾ç”¨", "é¸¡è‚‹",
    "æ‹”å¹²", "å¡çº¹", "æ‰è‰²", "æ°§åŒ–", "æš—æ²‰", "æ˜¾é»‘", "åšé‡", "æ²¹è…»", "ç²˜", "å‡ç™½",
    "ä¸æŒä¹…", "æ˜“æ‰", "æ˜“èŠ±", "æ–‘é©³", "ä¸å‡åŒ€", "ç»“å—", "èµ·çš®", "è¿‡æ•", "åˆºæ¿€",
    "ä¸æ˜¾è‰²", "éš¾æ¨", "éš¾å¸", "æµ®ç²‰", "å¡ç²‰", "è„±å¦†", "æ™•æŸ“", "é—·ç—˜", "è‡´ç—˜",
    
    # ä»·æ ¼ç›¸å…³
    "ä¸å€¼", "è´µ", "è´µäº†", "å¤ªè´µ", "æº¢ä»·", "ä¸åˆ’ç®—", "æ€§ä»·æ¯”ä½", "å‘é’±", "æ™ºå•†ç¨",
    "å®°å®¢", "é»‘å¿ƒ",
    
    # çœŸä¼ªé—®é¢˜
    "å‡", "å‡è´§", "éª—", "æ¬ºè¯ˆ", "ä»¿å†’", "ä¸æ˜¯æ­£å“", "æœ‰é—®é¢˜", "æ€€ç–‘", "ç›—ç‰ˆ",
    "å±±å¯¨", "ä»¿å“", "æ°´è´§", "éæ­£å“",
    
    # æœåŠ¡ç‰©æµ
    "é€€", "é€€è´§", "é€€æ¬¾", "æŠ•è¯‰", "ç»´æƒ", "æ‹’é€€", "æ€åº¦å·®", "ä¸ç†", "æ…¢", "å»¶è¿Ÿ",
    "ç ´æŸ", "æ¼", "ä¸¢", "ç¼º", "å°‘", "æ‹’ç»", "æ— å›åº”", "ä¸å›å¤", "æ•·è¡",
    
    # å…¶ä»–è´Ÿé¢
    "éš¾çœ‹", "ä¸‘", "è‡­", "åˆºé¼»", "çƒ‚", "å", "ç ´", "æ— è¯­", "ç”Ÿæ°”", "ç³Ÿç³•", "åŠ£è´¨",
    "å¤±è¯¯", "é—®é¢˜", "ç¼ºé™·", "ç‘•ç–µ", "ä¸æ»¡", "æŠ±æ€¨", "å·®è¯„",
    
    # è‹±æ–‡
    "bad", "worst", "terrible", "horrible", "awful", "poor", "disappointing",
    "waste", "cheap", "fake", "scam", "complaint", "refund", "broken", "damaged"
]

# Professional category framework
CATEGORY_FRAMEWORK = {
    "ğŸ¨ äº§å“ä½“éªŒ": {
        "keywords": [
            "è´¨åœ°", "æ˜¾è‰²", "æŒå¦†", "æŒä¹…", "æ‰è‰²", "æ‹”å¹²", "å¹²", "æ¶¦", "ä¿æ¹¿", "æ»‹æ¶¦",
            "å¡çº¹", "å”‡çº¹", "é¡ºæ»‘", "è½»è–„", "åšé‡", "æ°§åŒ–", "æ˜¾æ°”è‰²", "æ˜¾ç™½", "æ˜¾é»‘",
            "æœå¸–", "è‡ªç„¶", "ç»†è…»", "ä¸æ»‘", "æ°´æ¶¦", "æ¸…çˆ½", "æ²¹è…»", "ç²˜", "å‡ç™½",
            "å¦†æ„Ÿ", "ä¸Šå¦†", "æ™•æŸ“", "æµ®ç²‰", "å¡ç²‰", "è„±å¦†", "è¿‡æ•", "åˆºæ¿€", "é—·ç—˜",
            "texture", "lasting", "color", "dry", "smooth", "moisturizing"
        ],
        "description": "äº§å“è´¨åœ°ã€æ˜¾è‰²åº¦ã€æŒä¹…åº¦ã€ä¸Šå¦†æ•ˆæœç­‰æ ¸å¿ƒä½¿ç”¨ä½“éªŒ"
    },
    "ğŸ’° æ€§ä»·æ¯”": {
        "keywords": [
            "ä»·æ ¼", "æ€§ä»·æ¯”", "å€¼ä¸å€¼", "å€¼", "ä¸å€¼", "è´µ", "ä¾¿å®œ", "æº¢ä»·", "åˆ’ç®—",
            "ä¸åˆ’ç®—", "æ´»åŠ¨", "æŠ˜æ‰£", "ä¼˜æƒ ", "å®æƒ ", "è¶…å€¼", "ç‰©è¶…æ‰€å€¼", "å‘é’±",
            "æ™ºå•†ç¨", "ç™½èœä»·", "è‰¯å¿ƒä»·",
            "price", "value", "expensive", "cheap", "worth", "discount"
        ],
        "description": "ä»·æ ¼åˆç†æ€§ã€æ€§ä»·æ¯”è¯„ä¼°ã€ä¿ƒé”€æ»¡æ„åº¦"
    },
    "ğŸ“¦ åŒ…è£…è®¾è®¡": {
        "keywords": [
            "åŒ…è£…", "è´¨æ„Ÿ", "é«˜çº§", "é¢œå€¼", "å¥½çœ‹", "å¤–è§‚", "è®¾è®¡", "ç²¾è‡´", "å¤§æ°”",
            "æ—¶å°š", "å¥¢å", "æ¡£æ¬¡", "ç®€çº¦", "å¤å¤", "å¯çˆ±", "å°‘å¥³", "æˆç†Ÿ", "é›…è‡´",
            "åŒ…è£…ç›’", "ç“¶å­", "å¤–å£³", "ç›–å­",
            "packaging", "design", "appearance", "aesthetic", "premium", "elegant"
        ],
        "description": "å¤–åŒ…è£…è´¨æ„Ÿã€è§†è§‰è®¾è®¡ã€å“ç‰Œå½¢è±¡"
    },
    "ğŸšš ç‰©æµé…é€": {
        "keywords": [
            "ç‰©æµ", "å‘è´§", "åˆ°è´§", "å¿«é€’", "é…é€", "åŒ…è£…ç›’", "å¿«", "æ…¢", "åŠæ—¶",
            "å»¶è¿Ÿ", "ç ´æŸ", "æ¼æ¶²", "ä¸¢ä»¶", "å°‘ä»¶", "ç¼ºè´§", "ç­¾æ”¶", "æ”¶è´§",
            "delivery", "shipping", "logistics", "fast", "slow", "damaged", "late"
        ],
        "description": "é…é€é€Ÿåº¦ã€åŒ…è£…å®Œæ•´æ€§ã€ç‰©æµä½“éªŒ"
    },
    "ğŸ›¡ï¸ å”®åæœåŠ¡": {
        "keywords": [
            "å”®å", "å®¢æœ", "é€€è´§", "é€€æ¬¾", "æ‹’é€€", "æ¢è´§", "è¡¥å¿", "å¤„ç†", "æŠ•è¯‰",
            "æ€åº¦", "çƒ­æƒ…", "è€å¿ƒ", "ä¸“ä¸š", "å›å¤", "è§£å†³", "ç†èµ”", "ç»´æƒ",
            "service", "support", "refund", "return", "complaint", "response", "staff"
        ],
        "description": "å®¢æœå“åº”ã€é€€æ¢è´§æ”¿ç­–ã€é—®é¢˜å¤„ç†"
    },
    "âš ï¸ çœŸä¼ªé—®é¢˜": {
        "keywords": [
            "å‡è´§", "çœŸå‡", "æ­£å“", "æ¬ºè¯ˆ", "ç»´æƒ", "ä¸¾æŠ¥", "éª—", "ä»¿å†’", "ç›—ç‰ˆ",
            "ä¸‰æ— ", "å‡å†’", "éªŒè¯", "é˜²ä¼ª", "æˆæƒ", "å®˜æ–¹", "æ°´è´§", "å±±å¯¨",
            "fake", "authentic", "fraud", "counterfeit", "genuine", "trust", "real"
        ],
        "description": "äº§å“çœŸä¼ªã€å“ç‰Œä¿¡ä»»åº¦ã€é˜²ä¼ªéªŒè¯"
    },
    "ğŸ”„ ç«å“å¯¹æ¯”": {
        "keywords": [
            "ä¸å¦‚", "æ¯”èµ·", "ç›¸æ¯”", "å¯¹æ¯”", "æ›´å¥½", "æ›´å·®", "å·®ä¸å¤š", "ç±»ä¼¼",
            "å¹³æ›¿", "æ›¿ä»£", "åŒä»·ä½", "åŒæ¡£æ¬¡", "ç«å“", "å…¶ä»–å“ç‰Œ", "vs",
            "compare", "versus", "alternative", "better", "worse", "similar"
        ],
        "description": "ç«å“å¯¹æ¯”ã€å¹³æ›¿æ¨èã€ä¼˜åŠ£åˆ†æ"
    },
}

# Risk assessment thresholds
RISK_LEVELS = {
    "critical": {
        "threshold": 0.4,  # 40%+ negative
        "color": "#c0392b",
        "label": "ğŸ”´ ä¸¥é‡é£é™©",
        "action": "ç«‹å³åˆ é™¤/å…¬å…³å¤„ç†",
        "timeline": "2å°æ—¶å†…"
    },
    "high": {
        "threshold": 0.25,
        "color": "#e74c3c",
        "label": "ğŸŸ  é«˜é£é™©",
        "action": "è¯„ä¼°åˆ é™¤å¿…è¦æ€§",
        "timeline": "6å°æ—¶å†…"
    },
    "medium": {
        "threshold": 0.15,
        "color": "#f39c12",
        "label": "ğŸŸ¡ ä¸­é£é™©",
        "action": "ç›‘æµ‹å¹¶å‡†å¤‡å›åº”",
        "timeline": "24å°æ—¶å†…"
    },
    "low": {
        "threshold": 0,
        "color": "#2ecc71",
        "label": "ğŸŸ¢ ä½é£é™©",
        "action": "å¸¸è§„ç›‘æµ‹",
        "timeline": "å®šæœŸæ£€æŸ¥"
    }
}

# ============================================================
# ğŸ” ADVANCED KEYWORD EXTRACTION
# ============================================================

def build_dynamic_stopwords(brand_names: List[str], kol_names: List[str] = None) -> Set[str]:
    """Build dynamic stopwords including brands and KOLs"""
    stopwords = CHINESE_STOPWORDS.copy()
    stopwords.update(ENGLISH_STOPWORDS)
    
    # Add brand names
    for brand in brand_names:
        if brand:
            brand_lower = brand.lower().strip()
            stopwords.add(brand_lower)
            stopwords.add(brand.upper())
            stopwords.add(brand.title())
            stopwords.add(f"{brand_lower}å®¶")
            stopwords.add(f"{brand_lower}çš„")
    
    # Add KOL names
    if kol_names:
        for kol in kol_names:
            if kol:
                kol_lower = kol.lower().strip()
                stopwords.add(kol_lower)
                stopwords.add(f"@{kol_lower}")
    
    return stopwords

def extract_keywords_advanced(text: str, stopwords: Set[str]) -> List[str]:
    """Advanced keyword extraction"""
    text = str(text).strip().lower()
    keywords = []
    
    if JIEBA_AVAILABLE:
        jieba_words = jieba.cut(text, cut_all=False)
        for word in jieba_words:
            word = word.strip()
            if len(word) >= 2 and word not in stopwords:
                if not re.match(r'^\d+$', word):
                    if not re.match(r'^[a-z]$', word):
                        keywords.append(word)
    else:
        chinese = re.findall(r'[\u4e00-\u9fff]{2,6}', text)
        english = re.findall(r'[a-z]{3,20}', text)
        keywords = [w for w in chinese + english if w not in stopwords]
    
    return keywords

def categorize_keyword_smart(keyword: str) -> Tuple[str, str]:
    """Smart categorization"""
    kw_lower = keyword.lower()
    
    for category, info in CATEGORY_FRAMEWORK.items():
        for term in info["keywords"]:
            if term.lower() in kw_lower or kw_lower in term.lower():
                return category, info["description"]
    
    return "ğŸ“Œ å…¶ä»–æ´å¯Ÿ", "å…¶ä»–æ¶ˆè´¹è€…å…³æ³¨ç‚¹"

def extract_top_keywords_enhanced(
    posts: List[str],
    brand_names: List[str],
    kol_names: List[str] = None,
    min_frequency: int = 2,
    top_n: int = 20
) -> List[Dict[str, Any]]:
    """Enhanced keyword extraction"""
    
    if not posts:
        return []
    
    stopwords = build_dynamic_stopwords(brand_names, kol_names)
    keyword_posts_map = defaultdict(set)
    
    for idx, post in enumerate(posts):
        keywords = extract_keywords_advanced(post, stopwords)
        for kw in set(keywords):
            keyword_posts_map[kw].add(idx)
    
    keyword_counts = {kw: len(posts) for kw, posts in keyword_posts_map.items()}
    keyword_counts = {k: v for k, v in keyword_counts.items() if v >= min_frequency}
    
    ranked = sorted(keyword_counts.items(), key=lambda x: -x[1])[:top_n]
    
    results = []
    for keyword, count in ranked:
        category, cat_desc = categorize_keyword_smart(keyword)
        
        keyword_posts_list = [posts[idx] for idx in keyword_posts_map[keyword]]
        sentiment = calculate_sentiment_for_keyword(keyword_posts_list)
        
        # Determine priority
        if count >= 10:
            priority = "High"
            status = "ğŸ”´ æˆ˜ç•¥ä¼˜å…ˆ"
        elif count >= 5:
            priority = "Medium"
            status = "ğŸŸ  éªŒè¯æ¨¡å¼"
        else:
            priority = "Low"
            status = "ğŸŸ¡ æ–°å…´ä¿¡å·"
        
        results.append({
            "keyword": keyword,
            "mentions": count,
            "category": category,
            "category_desc": cat_desc,
            "priority": priority,
            "status": status,
            "sentiment_score": sentiment["net_sentiment"],
            "positive_ratio": sentiment["positive_pct"],
            "negative_ratio": sentiment["negative_pct"],
        })
    
    return results

# ============================================================
# ğŸ˜Š SENTIMENT ANALYSIS
# ============================================================

def analyze_sentiment(text: str) -> str:
    """Rule-based sentiment analysis"""
    text_lower = text.lower()
    
    pos_count = sum(1 for term in POSITIVE_TERMS if term in text_lower)
    neg_count = sum(1 for term in NEGATIVE_TERMS if term in text_lower)
    
    negation_patterns = ["ä¸å¤ª", "å¹¶ä¸", "ä¸æ˜¯å¾ˆ", "æ²¡é‚£ä¹ˆ", "not really", "not very"]
    has_negation = any(pattern in text_lower for pattern in negation_patterns)
    
    if has_negation:
        return "Neutral"
    
    if pos_count > neg_count and pos_count >= 1:
        return "Positive"
    elif neg_count > pos_count and neg_count >= 1:
        return "Negative"
    else:
        return "Neutral"

def calculate_sentiment_distribution(posts: List[str]) -> Dict[str, Any]:
    """Calculate sentiment metrics"""
    if not posts:
        return {
            "positive": 0, "negative": 0, "neutral": 0, "total": 0,
            "positive_pct": 0, "negative_pct": 0, "neutral_pct": 0,
            "net_sentiment": 0, "confidence": "æ•°æ®ä¸è¶³"
        }
    
    sentiments = [analyze_sentiment(post) for post in posts]
    counter = Counter(sentiments)
    total = len(sentiments)
    
    pos = counter.get("Positive", 0)
    neg = counter.get("Negative", 0)
    neu = counter.get("Neutral", 0)
    
    net_sentiment = (pos - neg) / total if total > 0 else 0
    
    if total < 10:
        confidence = "ä½ (æ ·æœ¬<10)"
    elif total < 30:
        confidence = "ä¸­ (æ ·æœ¬<30)"
    else:
        confidence = "é«˜ (æ ·æœ¬â‰¥30)"
    
    return {
        "positive": pos,
        "negative": neg,
        "neutral": neu,
        "total": total,
        "positive_pct": pos / total if total > 0 else 0,
        "negative_pct": neg / total if total > 0 else 0,
        "neutral_pct": neu / total if total > 0 else 0,
        "net_sentiment": net_sentiment,
        "confidence": confidence
    }

def calculate_sentiment_for_keyword(posts: List[str]) -> Dict[str, Any]:
    """Calculate sentiment for specific posts"""
    return calculate_sentiment_distribution(posts)

# ============================================================
# ğŸ¯ KOL CAMPAIGN MONITORING
# ============================================================

def assess_risk_level(negative_pct: float) -> Dict[str, str]:
    """Assess risk level based on negative percentage"""
    for level_name, level_info in RISK_LEVELS.items():
        if negative_pct >= level_info["threshold"]:
            return {
                "level": level_name,
                "label": level_info["label"],
                "color": level_info["color"],
                "action": level_info["action"],
                "timeline": level_info["timeline"]
            }
    return RISK_LEVELS["low"]

def analyze_kol_performance(
    kol_data: Dict[str, List[str]],
    brand_names: List[str]
) -> List[Dict[str, Any]]:
    """Analyze each KOL's comment performance"""
    
    results = []
    
    for kol_name, comments in kol_data.items():
        if not comments:
            continue
        
        # Sentiment analysis
        sentiment = calculate_sentiment_distribution(comments)
        
        # Risk assessment
        risk = assess_risk_level(sentiment["negative_pct"])
        
        # Keyword extraction
        keywords = extract_top_keywords_enhanced(
            comments, brand_names, [kol_name], min_frequency=1, top_n=10
        )
        
        # Find negative comments
        negative_comments = [
            c for c in comments if analyze_sentiment(c) == "Negative"
        ]
        
        results.append({
            "kol_name": kol_name,
            "total_comments": len(comments),
            "sentiment": sentiment,
            "risk": risk,
            "keywords": keywords,
            "negative_comments": negative_comments,
            "engagement_score": len(comments)  # Simple metric
        })
    
    return results

# ============================================================
# ğŸ“Š WORD CLOUD GENERATION
# ============================================================

def create_word_cloud(posts: List[str], brand_names: List[str], kol_names: List[str] = None, title: str = "è¯äº‘"):
    """Create word cloud"""
    if not WORDCLOUD_AVAILABLE or not posts:
        return None
    
    stopwords = build_dynamic_stopwords(brand_names, kol_names)
    
    all_keywords = []
    for post in posts:
        keywords = extract_keywords_advanced(post, stopwords)
        all_keywords.extend(keywords)
    
    if not all_keywords:
        return None
    
    keyword_freq = Counter(all_keywords)
    
    try:
           # --- Use font inside repo (works on Streamlit Cloud) ---
    base_dir = os.path.dirname(__file__)
    font_path = os.path.join(base_dir, "assets", "fonts", "NotoSansSC-Regular.otf")

    if not os.path.exists(font_path):
        st.warning("Chinese font not found in assets/fonts/. Please upload NotoSansSC-Regular.otf.")
        
        wc = WordCloud(
            width=1200,
            height=600,
            background_color='white',
            font_path=font_path,
            max_words=100,
            relative_scaling=0.5,
            colormap='viridis',
            prefer_horizontal=0.7,
            min_font_size=10,
            max_font_size=100
        ).generate_from_frequencies(keyword_freq)
        
        fig, ax = plt.subplots(figsize=(12, 6), facecolor='white')
        ax.imshow(wc, interpolation='bilinear')
        ax.axis('off')
        ax.set_title(title, fontsize=16, pad=20, weight='bold')
        
        plt.tight_layout(pad=0)
        
        return fig
        
    except Exception as e:
        st.warning(f"è¯äº‘ç”Ÿæˆå¤±è´¥: {str(e)}")
        return None

# ============================================================
# ğŸ“ˆ VISUALIZATIONS
# ============================================================

def create_sentiment_gauge(sentiment_data: Dict, brand_name: str):
    """Sentiment gauge chart"""
    if not PLOTLY_AVAILABLE:
        return None
    
    net_sentiment = sentiment_data.get("net_sentiment", 0)
    gauge_value = (net_sentiment + 1) * 50
    
    if net_sentiment > 0.3:
        color = "#2ecc71"
    elif net_sentiment > 0:
        color = "#f39c12"
    elif net_sentiment > -0.3:
        color = "#e74c3c"
    else:
        color = "#c0392b"
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = gauge_value,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {
            'text': f"<b>{brand_name}</b><br><span style='font-size:0.8em;color:gray'>å‡€æƒ…æ„ŸæŒ‡æ•°</span>",
            'font': {'size': 20}
        },
        delta = {'reference': 50, 'increasing': {'color': "green"}},
        gauge = {
            'axis': {'range': [None, 100], 'tickwidth': 1},
            'bar': {'color': color, 'thickness': 0.3},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 25], 'color': '#ffebee'},
                {'range': [25, 40], 'color': '#fff3e0'},
                {'range': [40, 60], 'color': '#fff9c4'},
                {'range': [60, 75], 'color': '#e8f5e9'},
                {'range': [75, 100], 'color': '#c8e6c9'}
            ],
            'threshold': {
                'line': {'color': "gray", 'width': 2},
                'thickness': 0.75,
                'value': 50
            }
        }
    ))
    
    fig.update_layout(
        height=300,
        font={'family': "Arial, sans-serif"},
        paper_bgcolor="rgba(0,0,0,0)",
        margin=dict(l=20, r=20, t=60, b=20)
    )
    
    return fig

def create_kol_comparison_chart(kol_results: List[Dict]):
    """KOL performance comparison"""
    if not PLOTLY_AVAILABLE or not kol_results:
        return None
    
    kol_names = [r["kol_name"] for r in kol_results]
    engagement = [r["engagement_score"] for r in kol_results]
    negative_pct = [r["sentiment"]["negative_pct"] * 100 for r in kol_results]
    positive_pct = [r["sentiment"]["positive_pct"] * 100 for r in kol_results]
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('è¯„è®ºæ•°é‡', 'æƒ…æ„Ÿåˆ†å¸ƒ'),
        specs=[[{'type': 'bar'}, {'type': 'bar'}]]
    )
    
    # Engagement
    fig.add_trace(
        go.Bar(x=kol_names, y=engagement, name="è¯„è®ºæ•°", marker_color='#3498db'),
        row=1, col=1
    )
    
    # Sentiment
    fig.add_trace(
        go.Bar(x=kol_names, y=positive_pct, name="æ­£é¢%", marker_color='#2ecc71'),
        row=1, col=2
    )
    fig.add_trace(
        go.Bar(x=kol_names, y=negative_pct, name="è´Ÿé¢%", marker_color='#e74c3c'),
        row=1, col=2
    )
    
    fig.update_layout(
        height=400,
        showlegend=True,
        title_text="<b>KOLè¡¨ç°å¯¹æ¯”</b>",
        barmode='group'
    )
    
    return fig

def create_risk_radar_chart(kol_results: List[Dict]):
    """Risk assessment radar chart"""
    if not PLOTLY_AVAILABLE or not kol_results:
        return None
    
    fig = go.Figure()
    
    for result in kol_results:
        kol_name = result["kol_name"]
        sentiment = result["sentiment"]
        
        # Calculate risk metrics
        categories = ['è´Ÿé¢ç‡', 'ä¸­æ€§ç‡', 'æ­£é¢ç‡', 'äº’åŠ¨é‡', 'é£é™©ç­‰çº§']
        
        risk_score_map = {"critical": 100, "high": 75, "medium": 50, "low": 25}
        risk_score = risk_score_map.get(result["risk"]["level"], 0)
        
        values = [
            sentiment["negative_pct"] * 100,
            sentiment["neutral_pct"] * 100,
            sentiment["positive_pct"] * 100,
            min(result["engagement_score"] / 10 * 100, 100),  # Normalize
            risk_score
        ]
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories,
            fill='toself',
            name=kol_name
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(visible=True, range=[0, 100])
        ),
        showlegend=True,
        title="<b>KOLé£é™©é›·è¾¾å›¾</b>",
        height=500
    )
    
    return fig

# ============================================================
# ğŸ¨ MODERN UI STYLING
# ============================================================

def apply_modern_styling():
    """Modern professional UI"""
    st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        
        * {
            font-family: 'Inter', 'Helvetica Neue', Arial, sans-serif;
        }
        
        .main {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        }
        
        .main-header {
            font-size: 3rem;
            font-weight: 700;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 0.5rem;
            letter-spacing: -1px;
        }
        
        .sub-header {
            font-size: 1.1rem;
            color: #6c757d;
            font-weight: 400;
            margin-bottom: 2rem;
        }
        
        .insight-card {
            background: white;
            border-radius: 16px;
            padding: 1.5rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.07);
            margin: 1rem 0;
            border: 1px solid #e9ecef;
            transition: all 0.3s ease;
        }
        
        .insight-card:hover {
            box-shadow: 0 8px 12px rgba(0,0,0,0.1);
            transform: translateY(-2px);
        }
        
        .explanation-box {
            background: linear-gradient(135deg, #e3f2fd 0%, #bbdefb 100%);
            border-left: 4px solid #2196f3;
            border-radius: 8px;
            padding: 1rem 1.2rem;
            margin: 1rem 0;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        
        .explanation-title {
            font-weight: 600;
            color: #1976d2;
            margin-bottom: 0.5rem;
            font-size: 1rem;
        }
        
        .metric-container {
            background: white;
            border-radius: 12px;
            padding: 1.2rem;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
            border: 1px solid #e9ecef;
        }
        
        .metric-value {
            font-size: 2rem;
            font-weight: 700;
            color: #2c3e50;
            margin: 0.5rem 0;
        }
        
        .metric-label {
            font-size: 0.85rem;
            color: #6c757d;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }
        
        .risk-critical {
            background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
            border-left: 5px solid #c0392b;
            border-radius: 12px;
            padding: 1.2rem;
            margin: 0.8rem 0;
        }
        
        .risk-high {
            background: linear-gradient(135deg, #ffebee 0%, #ffcdd2 100%);
            border-left: 5px solid #e74c3c;
            border-radius: 12px;
            padding: 1.2rem;
            margin: 0.8rem 0;
        }
        
        .risk-medium {
            background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
            border-left: 5px solid #f39c12;
            border-radius: 12px;
            padding: 1.2rem;
            margin: 0.8rem 0;
        }
        
        .risk-low {
            background: linear-gradient(135deg, #e8f5e9 0%, #c8e6c9 100%);
            border-left: 5px solid #2ecc71;
            border-radius: 12px;
            padding: 1.2rem;
            margin: 0.8rem 0;
        }
        
        .stTabs [data-baseweb="tab-list"] {
            gap: 0.5rem;
            background-color: white;
            padding: 0.8rem;
            border-radius: 12px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        
        .stTabs [data-baseweb="tab"] {
            height: 3rem;
            font-size: 0.95rem;
            font-weight: 500;
            border-radius: 8px;
            padding: 0 1.5rem;
            color: #6c757d;
        }
        
        .stTabs [aria-selected="true"] {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            box-shadow: 0 4px 6px rgba(102, 126, 234, 0.3);
        }
        
        .block-container {
            padding-top: 2rem;
            padding-bottom: 2rem;
        }
    </style>
    """, unsafe_allow_html=True)

# ============================================================
# ğŸ“„ CAMPAIGN REPORT GENERATION
# ============================================================

def generate_campaign_report_data(
    campaign_name: str,
    kol_results: List[Dict],
    brand_name: str
) -> Dict[str, Any]:
    """Generate comprehensive campaign report data"""
    
    # Overall metrics
    total_comments = sum(r["total_comments"] for r in kol_results)
    total_negative = sum(len(r["negative_comments"]) for r in kol_results)
    
    # Average sentiment
    avg_positive = np.mean([r["sentiment"]["positive_pct"] for r in kol_results])
    avg_negative = np.mean([r["sentiment"]["negative_pct"] for r in kol_results])
    avg_neutral = np.mean([r["sentiment"]["neutral_pct"] for r in kol_results])
    
    # Risk summary
    risk_counts = Counter([r["risk"]["level"] for r in kol_results])
    
    # Top issues
    all_negative_comments = []
    for r in kol_results:
        all_negative_comments.extend(r["negative_comments"])
    
    negative_keywords = extract_top_keywords_enhanced(
        all_negative_comments,
        [brand_name],
        min_frequency=1,
        top_n=10
    ) if all_negative_comments else []
    
    return {
        "campaign_name": campaign_name,
        "brand_name": brand_name,
        "date": date.today().strftime("%Y-%m-%d"),
        "kol_count": len(kol_results),
        "total_comments": total_comments,
        "total_negative": total_negative,
        "avg_positive_pct": avg_positive,
        "avg_negative_pct": avg_negative,
        "avg_neutral_pct": avg_neutral,
        "risk_summary": {
            "critical": risk_counts.get("critical", 0),
            "high": risk_counts.get("high", 0),
            "medium": risk_counts.get("medium", 0),
            "low": risk_counts.get("low", 0)
        },
        "kol_results": kol_results,
        "negative_keywords": negative_keywords
    }

# ============================================================
# ğŸ“± STREAMLIT APP
# ============================================================

st.set_page_config(
    page_title="å“ç‰Œæ´å¯Ÿå¹³å° Ultimate",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

apply_modern_styling()

# Header
st.markdown('<div class="main-header">ğŸ¯ å“ç‰Œæ´å¯Ÿå¹³å° Ultimate Edition</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">McKinseyçº§åˆ†æ Â· KOLç›‘æµ‹ Â· Campaignè¿½è¸ª Â· é£é™©è¯„ä¼° Â· æ™ºèƒ½æŠ¥å‘Š</div>', unsafe_allow_html=True)

# ============================================================
# SIDEBAR
# ============================================================

with st.sidebar:
    st.markdown("### âš™ï¸ åˆ†æé…ç½®")
    
    data_source = st.selectbox(
        "æ•°æ®æ¥æº",
        ["ğŸ” å°çº¢ä¹¦", "ğŸ›’ ç”µå•†è¯„è®º", "ğŸ“± æŠ–éŸ³", "ğŸ’¬ å¾®åš"]
    )
    
    st.markdown("---")
    st.markdown("### ğŸ¢ å“ç‰Œè®¾ç½®")
    
    primary_brand = st.text_input("ä¸»å“ç‰Œåç§°", value="YSL")
    
    enable_competitor = st.toggle("å¯ç”¨ç«å“åˆ†æ", value=False)
    
    if enable_competitor:
        competitor_brand = st.text_input("ç«å“åç§°", value="Dior")
    else:
        competitor_brand = ""
    
    st.markdown("---")
    st.markdown("### ğŸ‘¥ KOLç›‘æµ‹")
    
    enable_kol_monitoring = st.toggle("å¯ç”¨KOLç›‘æµ‹", value=False)
    
    if enable_kol_monitoring:
        campaign_name = st.text_input("Campaignåç§°", value="æ˜¥å­£æ–°å“æ¨å¹¿")
        
        kol_input = st.text_area(
            "è¾“å…¥KOLåç§°ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
            value="æä½³ç¦\nè–‡å¨…\néª†ç‹å®‡",
            height=100
        )
        kol_names_list = [name.strip() for name in kol_input.split('\n') if name.strip()]
    else:
        campaign_name = ""
        kol_names_list = []
    
    st.markdown("---")
    
    with st.expander("ğŸ”§ é«˜çº§è®¾ç½®"):
        min_frequency = st.slider("æœ€å°å…³é”®è¯é¢‘æ¬¡", 1, 5, 2)
        top_n = st.slider("å±•ç¤ºå…³é”®è¯æ•°é‡", 10, 30, 20)
        enable_wordcloud = st.checkbox("å¯ç”¨è¯äº‘", value=True)
        risk_auto_flag = st.checkbox("è‡ªåŠ¨æ ‡è®°é«˜é£é™©", value=True)
    
    st.markdown("---")
    st.markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
    
    if PLOTLY_AVAILABLE:
        st.success("âœ… å›¾è¡¨å¼•æ“")
    if JIEBA_AVAILABLE:
        st.success("âœ… ä¸­æ–‡åˆ†è¯")
    if WORDCLOUD_AVAILABLE:
        st.success("âœ… è¯äº‘ç”Ÿæˆ")

# ============================================================
# MAIN TABS
# ============================================================

if enable_kol_monitoring:
    tabs = st.tabs([
        "ğŸ“¥ æ•°æ®è¾“å…¥",
        "ğŸ“Š åˆ†æçœ‹æ¿",
        "ğŸ‘¥ KOLç›‘æµ‹",
        "âš ï¸ é£é™©è¯„ä¼°",
        "ğŸ“„ CampaignæŠ¥å‘Š"
    ])
    
    tab_input = tabs[0]
    tab_dashboard = tabs[1]
    tab_kol = tabs[2]
    tab_risk = tabs[3]
    tab_campaign = tabs[4]
else:
    tabs = st.tabs([
        "ğŸ“¥ æ•°æ®è¾“å…¥",
        "ğŸ“Š åˆ†æçœ‹æ¿",
        "ğŸ˜Š æƒ…æ„Ÿåˆ†æ",
        "ğŸ’¡ æˆ˜ç•¥æ´å¯Ÿ",
        "ğŸ“„ æŠ¥å‘Šå¯¼å‡º"
    ])
    
    tab_input = tabs[0]
    tab_dashboard = tabs[1]
    tab_sentiment = tabs[2]
    tab_insights = tabs[3]
    tab_report = tabs[4]

# Initialize session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

if 'kol_analysis' not in st.session_state:
    st.session_state.kol_analysis = None

# ============================================================
# TAB 1: DATA INPUT
# ============================================================

with tab_input:
    st.markdown("## ğŸ“¥ æ•°æ®è¾“å…¥")
    
    st.markdown("""
    <div class="explanation-box">
        <div class="explanation-title">ğŸ“– ä½¿ç”¨è¯´æ˜</div>
        <strong>å¸¸è§„åˆ†æï¼š</strong>ä¸Šä¼ å“ç‰Œè¯„è®ºæ•°æ®è¿›è¡Œæƒ…æ„Ÿåˆ†æå’Œå…³é”®è¯æå–<br>
        <strong>KOLç›‘æµ‹ï¼š</strong>å¯ç”¨åï¼Œå¯æŒ‰KOLåˆ†åˆ«ä¸Šä¼ è¯„è®ºï¼Œè¿›è¡Œé£é™©è¯„ä¼°å’ŒCampaignè¿½è¸ª<br>
        <strong>å»ºè®®æ ·æœ¬é‡ï¼š</strong>æ¯ä¸ªKOL 20+æ¡è¯„è®ºï¼Œæ•´ä½“30+æ¡ä»¥è·å¾—å‡†ç¡®æ´å¯Ÿ
    </div>
    """, unsafe_allow_html=True)
    
    def load_data_simple(label: str, key: str) -> List[str]:
        """Simple data loading"""
        st.markdown(f"### {label}")
        
        uploaded_file = st.file_uploader(f"ä¸Šä¼ CSV", type=["csv"], key=f"{key}_file")
        
        posts = []
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                
                text_col = st.selectbox(f"é€‰æ‹©æ–‡æœ¬åˆ—", df.columns.tolist(), key=f"{key}_col")
                
                raw_posts = df[text_col].dropna().astype(str).tolist()
                
                seen = set()
                for post in raw_posts:
                    post = post.strip()
                    if len(post) >= 5 and post not in seen:
                        posts.append(post)
                        seen.add(post)
                
                st.success(f"âœ… å·²åŠ è½½ {len(posts)} æ¡è¯„è®º")
                
            except Exception as e:
                st.error(f"âŒ åŠ è½½å¤±è´¥: {str(e)}")
        
        manual_input = st.text_area(
            f"æˆ–æ‰‹åŠ¨ç²˜è´´è¯„è®ºï¼ˆæ¯è¡Œä¸€æ¡ï¼‰",
            height=150,
            key=f"{key}_manual"
        )
        
        if manual_input.strip() and not posts:
            lines = manual_input.strip().split('\n')
            seen = set()
            for line in lines:
                line = line.strip()
                if len(line) >= 5 and line not in seen:
                    posts.append(line)
                    seen.add(line)
            
            if posts:
                st.success(f"âœ… å·²åŠ è½½ {len(posts)} æ¡è¯„è®º")
        
        return posts
    
    if enable_kol_monitoring:
        st.markdown("### ğŸ‘¥ æŒ‰KOLåˆ†åˆ«ä¸Šä¼ æ•°æ®")
        
        kol_data_dict = {}
        
        cols = st.columns(min(len(kol_names_list), 3))
        
        for idx, kol_name in enumerate(kol_names_list):
            with cols[idx % 3]:
                posts = load_data_simple(f"ğŸ“± {kol_name}", f"kol_{idx}")
                if posts:
                    kol_data_dict[kol_name] = posts
        
        if st.button("ğŸ’¾ ä¿å­˜KOLæ•°æ®", type="primary"):
            st.session_state.kol_data = kol_data_dict
            st.success(f"âœ… å·²ä¿å­˜ {len(kol_data_dict)} ä¸ªKOLçš„æ•°æ®")
    
    else:
        # Regular data input
        col_brand_1, col_brand_2 = st.columns(2)
        
        with col_brand_1:
            primary_posts = load_data_simple(f"ğŸ¯ {primary_brand}", "primary")
        
        with col_brand_2:
            if enable_competitor:
                competitor_posts = load_data_simple(f"ğŸ”„ {competitor_brand}", "competitor")
            else:
                competitor_posts = []

# ============================================================
# TAB 2: ANALYSIS DASHBOARD
# ============================================================

with tab_dashboard:
    st.markdown("## ğŸ“Š ç»¼åˆåˆ†æçœ‹æ¿")
    
    if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ", type="primary", use_container_width=True):
        
        if enable_kol_monitoring:
            if not hasattr(st.session_state, 'kol_data') or not st.session_state.kol_data:
                st.error("âš ï¸ è¯·å…ˆåœ¨'æ•°æ®è¾“å…¥'æ ‡ç­¾é¡µä¸Šä¼ KOLæ•°æ®")
                st.stop()
            
            with st.spinner("ğŸ”„ åˆ†æKOLæ•°æ®ä¸­..."):
                kol_results = analyze_kol_performance(
                    st.session_state.kol_data,
                    [primary_brand]
                )
                
                st.session_state.kol_analysis = {
                    "campaign_name": campaign_name,
                    "brand_name": primary_brand,
                    "kol_results": kol_results,
                    "brand_names": [primary_brand]
                }
                
                st.success("âœ… KOLåˆ†æå®Œæˆï¼")
        
        else:
            if 'primary_posts' not in locals() or not primary_posts:
                st.error("âš ï¸ è¯·å…ˆåœ¨'æ•°æ®è¾“å…¥'æ ‡ç­¾é¡µæä¾›æ•°æ®")
                st.stop()
            
            with st.spinner("ğŸ”„ åˆ†æä¸­..."):
                brand_names = [primary_brand]
                if enable_competitor and competitor_brand:
                    brand_names.append(competitor_brand)
                
                primary_keywords = extract_top_keywords_enhanced(
                    primary_posts, brand_names, min_frequency=min_frequency, top_n=top_n
                )
                primary_sentiment = calculate_sentiment_distribution(primary_posts)
                
                if enable_competitor and 'competitor_posts' in locals() and competitor_posts:
                    competitor_keywords = extract_top_keywords_enhanced(
                        competitor_posts, brand_names, min_frequency=min_frequency, top_n=top_n
                    )
                    competitor_sentiment = calculate_sentiment_distribution(competitor_posts)
                else:
                    competitor_keywords = []
                    competitor_sentiment = {}
                
                st.session_state.analysis_results = {
                    "primary": {
                        "brand": primary_brand,
                        "posts": primary_posts,
                        "keywords": primary_keywords,
                        "sentiment": primary_sentiment,
                    },
                    "competitor": {
                        "brand": competitor_brand,
                        "posts": competitor_posts,
                        "keywords": competitor_keywords,
                        "sentiment": competitor_sentiment,
                    } if enable_competitor and competitor_posts else None,
                    "brand_names": brand_names
                }
                
                st.success("âœ… åˆ†æå®Œæˆï¼")
    
    # Display results
    if enable_kol_monitoring and st.session_state.kol_analysis:
        kol_analysis = st.session_state.kol_analysis
        kol_results = kol_analysis["kol_results"]
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ Campaignæ€»è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        total_comments = sum(r["total_comments"] for r in kol_results)
        total_negative = sum(len(r["negative_comments"]) for r in kol_results)
        avg_negative_pct = np.mean([r["sentiment"]["negative_pct"] for r in kol_results])
        high_risk_count = sum(1 for r in kol_results if r["risk"]["level"] in ["critical", "high"])
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">æ€»è¯„è®ºæ•°</div>
                <div class="metric-value">{total_comments}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">è´Ÿé¢è¯„è®º</div>
                <div class="metric-value" style="color:#e74c3c;">{total_negative}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">å¹³å‡è´Ÿé¢ç‡</div>
                <div class="metric-value" style="color:{'#e74c3c' if avg_negative_pct > 0.25 else '#f39c12'};">{avg_negative_pct:.1%}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">é«˜é£é™©KOL</div>
                <div class="metric-value" style="color:{'#c0392b' if high_risk_count > 0 else '#2ecc71'};">{high_risk_count}</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # KOL comparison charts
        if PLOTLY_AVAILABLE:
            st.markdown("### ğŸ“Š KOLè¡¨ç°å¯¹æ¯”")
            
            st.markdown("""
            <div class="explanation-box">
                <div class="explanation-title">ğŸ“– å›¾è¡¨è¯´æ˜</div>
                <strong>å·¦å›¾ï¼š</strong>å„KOLçš„è¯„è®ºäº’åŠ¨é‡<br>
                <strong>å³å›¾ï¼š</strong>å„KOLçš„æ­£é¢/è´Ÿé¢è¯„è®ºå æ¯”<br>
                <strong>é›·è¾¾å›¾ï¼š</strong>å¤šç»´åº¦é£é™©è¯„ä¼°ï¼ˆè¶Šé å¤–åœˆé£é™©è¶Šé«˜ï¼‰
            </div>
            """, unsafe_allow_html=True)
            
            fig_comparison = create_kol_comparison_chart(kol_results)
            if fig_comparison:
                st.plotly_chart(fig_comparison, use_container_width=True)
            
            fig_radar = create_risk_radar_chart(kol_results)
            if fig_radar:
                st.plotly_chart(fig_radar, use_container_width=True)
        
        # Word clouds
        if enable_wordcloud and WORDCLOUD_AVAILABLE:
            st.markdown("---")
            st.markdown("### â˜ï¸ KOLè¯äº‘å¯¹æ¯”")
            
            st.markdown("""
            <div class="explanation-box">
                <div class="explanation-title">ğŸ“– è¯äº‘è¯´æ˜</div>
                å±•ç¤ºå„KOLè¯„è®ºåŒºçš„é«˜é¢‘å…³é”®è¯ï¼Œå­—ä½“å¤§å°ä»£è¡¨æåŠé¢‘ç‡ã€‚å·²è‡ªåŠ¨è¿‡æ»¤KOLåç§°å’Œæ— æ„ä¹‰è¯ã€‚
            </div>
            """, unsafe_allow_html=True)
            
            cols_wc = st.columns(min(len(kol_results), 3))
            
            for idx, result in enumerate(kol_results):
                with cols_wc[idx % 3]:
                    st.markdown(f"#### {result['kol_name']}")
                    
                    if result["total_comments"] > 0:
                        all_comments = st.session_state.kol_data.get(result["kol_name"], [])
                        wc_fig = create_word_cloud(
                            all_comments,
                            [primary_brand],
                            [result["kol_name"]],
                            f"{result['kol_name']} è¯„è®ºè¯äº‘"
                        )
                        if wc_fig:
                            st.pyplot(wc_fig)
                            plt.close()
    
    elif st.session_state.analysis_results:
        # Regular analysis display
        results = st.session_state.analysis_results
        primary_data = results["primary"]
        
        st.markdown("---")
        st.markdown("### ğŸ“ˆ å¿«é€Ÿæ¦‚è§ˆ")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">æ ·æœ¬é‡</div>
                <div class="metric-value">{len(primary_data["posts"])}</div>
                <div style="font-size:0.8rem;color:#6c757d;">{primary_data["sentiment"]["confidence"]}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            net_sent = primary_data["sentiment"]["net_sentiment"]
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">å‡€æƒ…æ„Ÿ</div>
                <div class="metric-value" style="color:{'#2ecc71' if net_sent > 0.2 else '#e74c3c' if net_sent < -0.2 else '#f39c12'};">{net_sent:.2f}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            high_priority = sum(1 for kw in primary_data["keywords"] if kw["priority"] == "High")
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">é«˜ä¼˜å…ˆçº§</div>
                <div class="metric-value" style="color:{'#e74c3c' if high_priority > 0 else '#2ecc71'};">{high_priority}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">å…³é”®è¯</div>
                <div class="metric-value">{len(primary_data["keywords"])}</div>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # Visualizations
        if PLOTLY_AVAILABLE:
            st.markdown("### ğŸ“Š å¯è§†åŒ–æ´å¯Ÿ")
            
            st.markdown("""
            <div class="explanation-box">
                <div class="explanation-title">ğŸ“– å›¾è¡¨è¯´æ˜</div>
                <strong>æƒ…æ„Ÿä»ªè¡¨ç›˜ï¼š</strong>æ•´ä½“æƒ…æ„Ÿå€¾å‘ï¼Œ50ä¸ºä¸­æ€§ï¼Œè¶Šé«˜è¶Šæ­£é¢<br>
                <strong>è¯äº‘ï¼š</strong>å­—ä½“å¤§å°=æåŠé¢‘ç‡ï¼Œé¢œè‰²ä»…ç”¨äºåŒºåˆ†
            </div>
            """, unsafe_allow_html=True)
            
            fig_gauge = create_sentiment_gauge(primary_data["sentiment"], primary_brand)
            if fig_gauge:
                st.plotly_chart(fig_gauge, use_container_width=True)
        
        # Word clouds
        if enable_wordcloud and WORDCLOUD_AVAILABLE:
            st.markdown("---")
            st.markdown("### â˜ï¸ å…³é”®è¯è¯äº‘")
            
            wc_fig = create_word_cloud(
                primary_data["posts"],
                results["brand_names"],
                title=f"{primary_brand} é«˜é¢‘å…³é”®è¯"
            )
            if wc_fig:
                st.pyplot(wc_fig)
                plt.close()

# ============================================================
# TAB 3: KOL MONITORING (if enabled) or SENTIMENT ANALYSIS
# ============================================================

if enable_kol_monitoring:
    with tab_kol:
        st.markdown("## ğŸ‘¥ KOLè¯¦ç»†ç›‘æµ‹")
        
        if not st.session_state.kol_analysis:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        kol_analysis = st.session_state.kol_analysis
        kol_results = kol_analysis["kol_results"]
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– KOLç›‘æµ‹è¯´æ˜</div>
            é’ˆå¯¹æ¯ä¸ªKOLçš„è¯„è®ºåŒºè¿›è¡Œç‹¬ç«‹åˆ†æï¼Œè¯„ä¼°äº’åŠ¨è´¨é‡å’Œæ½œåœ¨é£é™©ã€‚<br>
            <strong>ç»¿è‰²</strong>=ä½é£é™©ï¼Œ<strong>é»„è‰²</strong>=ä¸­é£é™©ï¼Œ<strong>æ©™è‰²</strong>=é«˜é£é™©ï¼Œ<strong>çº¢è‰²</strong>=ä¸¥é‡é£é™©
        </div>
        """, unsafe_allow_html=True)
        
        for result in kol_results:
            kol_name = result["kol_name"]
            sentiment = result["sentiment"]
            risk = result["risk"]
            
            risk_class = f"risk-{risk['level']}"
            
            with st.container():
                st.markdown(f"""
                <div class="{risk_class}">
                    <h3>ğŸ“± {kol_name}</h3>
                    <strong>é£é™©ç­‰çº§ï¼š</strong>{risk['label']}<br>
                    <strong>è¯„è®ºæ•°ï¼š</strong>{result['total_comments']} æ¡<br>
                    <strong>æƒ…æ„Ÿåˆ†å¸ƒï¼š</strong>æ­£é¢ {sentiment['positive_pct']:.1%} | ä¸­æ€§ {sentiment['neutral_pct']:.1%} | è´Ÿé¢ {sentiment['negative_pct']:.1%}<br>
                    <strong>å»ºè®®è¡ŒåŠ¨ï¼š</strong>{risk['action']}<br>
                    <strong>å¤„ç†æ—¶é™ï¼š</strong>{risk['timeline']}
                </div>
                """, unsafe_allow_html=True)
                
                if result["negative_comments"]:
                    with st.expander(f"âš ï¸ æŸ¥çœ‹è´Ÿé¢è¯„è®º ({len(result['negative_comments'])}æ¡)"):
                        for idx, comment in enumerate(result["negative_comments"][:10], 1):
                            st.markdown(f"{idx}. {comment}")
                        
                        if len(result["negative_comments"]) > 10:
                            st.info(f"è¿˜æœ‰ {len(result['negative_comments']) - 10} æ¡è´Ÿé¢è¯„è®ºæœªæ˜¾ç¤º")
                
                if result["keywords"]:
                    with st.expander(f"ğŸ”‘ å…³é”®è¯åˆ†æ (Top {len(result['keywords'])})"):
                        df_kw = pd.DataFrame(result["keywords"])
                        st.dataframe(
                            df_kw[["keyword", "mentions", "category", "sentiment_score"]],
                            use_container_width=True,
                            hide_index=True
                        )
                
                st.markdown("---")

else:
    with tab_sentiment:
        st.markdown("## ğŸ˜Š æƒ…æ„Ÿåˆ†æ")
        
        if not st.session_state.analysis_results:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        results = st.session_state.analysis_results
        primary_data = results["primary"]
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– æƒ…æ„Ÿåˆ†æè¯´æ˜</div>
            åŸºäºæ­£è´Ÿé¢å…³é”®è¯è§„åˆ™åˆ¤æ–­æ¯æ¡è¯„è®ºæƒ…æ„Ÿå€¾å‘ã€‚<br>
            <strong>å‡€æƒ…æ„Ÿåˆ†æ•° = (æ­£é¢ - è´Ÿé¢) / æ€»æ•°</strong>ï¼ŒèŒƒå›´ -1 åˆ° +1
        </div>
        """, unsafe_allow_html=True)
        
        sent_data = primary_data["sentiment"]
        
        col_a, col_b, col_c = st.columns(3)
        col_a.metric("ğŸ˜Š æ­£é¢", f"{sent_data['positive_pct']:.1%}", delta=f"{sent_data['positive']}æ¡")
        col_b.metric("ğŸ˜ ä¸­æ€§", f"{sent_data['neutral_pct']:.1%}", delta=f"{sent_data['neutral']}æ¡")
        col_c.metric("ğŸ˜ è´Ÿé¢", f"{sent_data['negative_pct']:.1%}", delta=f"{sent_data['negative']}æ¡", delta_color="inverse")

# ============================================================
# TAB 4: RISK ASSESSMENT or STRATEGIC INSIGHTS
# ============================================================

if enable_kol_monitoring:
    with tab_risk:
        st.markdown("## âš ï¸ é£é™©è¯„ä¼°ä¸åº”å¯¹å»ºè®®")
        
        if not st.session_state.kol_analysis:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        kol_analysis = st.session_state.kol_analysis
        kol_results = kol_analysis["kol_results"]
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– é£é™©è¯„ä¼°æ ‡å‡†</div>
            <strong>ğŸ”´ ä¸¥é‡é£é™©(â‰¥40%è´Ÿé¢)ï¼š</strong>ç«‹å³åˆ é™¤è´Ÿé¢è¯„è®ºæˆ–å¯åŠ¨å…¬å…³åº”å¯¹<br>
            <strong>ğŸŸ  é«˜é£é™©(25-40%è´Ÿé¢)ï¼š</strong>è¯„ä¼°åˆ é™¤å¿…è¦æ€§ï¼Œå‡†å¤‡å›åº”è¯æœ¯<br>
            <strong>ğŸŸ¡ ä¸­é£é™©(15-25%è´Ÿé¢)ï¼š</strong>å¯†åˆ‡ç›‘æµ‹ï¼Œå‡†å¤‡åº”å¯¹é¢„æ¡ˆ<br>
            <strong>ğŸŸ¢ ä½é£é™©(<15%è´Ÿé¢)ï¼š</strong>å¸¸è§„ç›‘æµ‹å³å¯
        </div>
        """, unsafe_allow_html=True)
        
        # High risk KOLs
        high_risk_kols = [r for r in kol_results if r["risk"]["level"] in ["critical", "high"]]
        
        if high_risk_kols:
            st.markdown("### ğŸš¨ éœ€è¦ç«‹å³å¤„ç†çš„KOL")
            
            for result in high_risk_kols:
                risk_class = f"risk-{result['risk']['level']}"
                
                st.markdown(f"""
                <div class="{risk_class}">
                    <h4>{result['risk']['label']} {result['kol_name']}</h4>
                    <strong>è´Ÿé¢ç‡ï¼š</strong>{result['sentiment']['negative_pct']:.1%} ({len(result['negative_comments'])}æ¡)<br>
                    <strong>å»ºè®®è¡ŒåŠ¨ï¼š</strong><br>
                    1. {result['risk']['action']}<br>
                    2. è”ç³»KOLæ²Ÿé€šåˆ é™¤äº‹å®œ<br>
                    3. å‡†å¤‡å®˜æ–¹å›åº”è¯æœ¯<br>
                    4. ç›‘æµ‹åç»­èˆ†æƒ…å˜åŒ–<br>
                    <strong>å¤„ç†æ—¶é™ï¼š</strong><span style="color:red;font-weight:bold;">{result['risk']['timeline']}</span>
                </div>
                """, unsafe_allow_html=True)
                
                # Action plan
                with st.expander("ğŸ“‹ è¯¦ç»†åº”å¯¹æ–¹æ¡ˆ"):
                    st.markdown(f"""
                    **Step 1: è¯„ä¼°åˆ é™¤å¿…è¦æ€§**
                    - è´Ÿé¢è¯„è®ºæ•°é‡: {len(result['negative_comments'])}æ¡
                    - æ˜¯å¦æ¶‰åŠäº§å“è´¨é‡é—®é¢˜: éœ€äººå·¥åˆ¤æ–­
                    - æ˜¯å¦æ¶‰åŠè™šå‡å®£ä¼ : éœ€äººå·¥åˆ¤æ–­
                    
                    **Step 2: è”ç³»KOL**
                    - å‘é€åˆ é™¤è¯·æ±‚é‚®ä»¶
                    - è¯´æ˜ç†ç”±å’Œå½±å“
                    - æä¾›è¡¥å¿æ–¹æ¡ˆï¼ˆå¦‚éœ€è¦ï¼‰
                    
                    **Step 3: å…¬å…³åº”å¯¹**
                    - å‡†å¤‡å®˜æ–¹å£°æ˜
                    - åœ¨å…¶ä»–å¹³å°å‘å¸ƒæ­£é¢å†…å®¹
                    - ç›‘æµ‹å“ç‰Œèˆ†æƒ…å˜åŒ–
                    
                    **Step 4: æŒç»­è¿½è¸ª**
                    - æ¯2å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                    - è®°å½•å¤„ç†è¿›å±•
                    - è¯„ä¼°æ•ˆæœ
                    """)
                
                st.markdown("---")
        
        else:
            st.success("âœ… å½“å‰æ— é«˜é£é™©KOLï¼Œç»§ç»­ä¿æŒç›‘æµ‹")
        
        # All KOLs summary
        st.markdown("### ğŸ“Š å…¨éƒ¨KOLé£é™©æ€»è§ˆ")
        
        risk_summary_data = []
        for result in kol_results:
            risk_summary_data.append({
                "KOL": result["kol_name"],
                "è¯„è®ºæ•°": result["total_comments"],
                "è´Ÿé¢æ•°": len(result["negative_comments"]),
                "è´Ÿé¢ç‡": f"{result['sentiment']['negative_pct']:.1%}",
                "é£é™©ç­‰çº§": result["risk"]["label"],
                "å»ºè®®è¡ŒåŠ¨": result["risk"]["action"]
            })
        
        df_risk = pd.DataFrame(risk_summary_data)
        st.dataframe(df_risk, use_container_width=True, hide_index=True)

else:
    with tab_insights:
        st.markdown("## ğŸ’¡ æˆ˜ç•¥æ´å¯Ÿ")
        
        if not st.session_state.analysis_results:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        results = st.session_state.analysis_results
        primary_data = results["primary"]
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– æˆ˜ç•¥å»ºè®®è¯´æ˜</div>
            åŸºäºå…³é”®è¯é¢‘æ¬¡å’Œæƒ…æ„Ÿè‡ªåŠ¨ç”Ÿæˆä¼˜å…ˆçº§å»ºè®®ã€‚<br>
            <strong>é«˜ä¼˜å…ˆçº§(â‰¥10æ¬¡)ï¼š</strong>24-48hå¤„ç†<br>
            <strong>ä¸­ä¼˜å…ˆçº§(5-9æ¬¡)ï¼š</strong>1å‘¨å†…å¤„ç†<br>
            <strong>ä½ä¼˜å…ˆçº§(2-4æ¬¡)ï¼š</strong>2å‘¨å†…ç›‘æµ‹
        </div>
        """, unsafe_allow_html=True)
        
        high_priority = [kw for kw in primary_data["keywords"] if kw["priority"] == "High"]
        
        if high_priority:
            st.markdown("### ğŸ”´ é«˜ä¼˜å…ˆçº§")
            for kw in high_priority:
                st.markdown(f"""
                <div class="risk-high">
                    <h4>{kw['keyword']} ({kw['category']})</h4>
                    <strong>æåŠï¼š</strong>{kw['mentions']}æ¬¡<br>
                    <strong>æƒ…æ„Ÿï¼š</strong>{kw['sentiment_score']:.2f}<br>
                    <strong>è¡ŒåŠ¨ï¼š</strong>ç«‹å³å¤„ç†ç›¸å…³é—®é¢˜
                </div>
                """, unsafe_allow_html=True)

# ============================================================
# TAB 5: CAMPAIGN REPORT or EXPORT
# ============================================================

if enable_kol_monitoring:
    with tab_campaign:
        st.markdown("## ğŸ“„ Campaignåˆ†ææŠ¥å‘Š")
        
        if not st.session_state.kol_analysis:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        kol_analysis = st.session_state.kol_analysis
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– æŠ¥å‘Šè¯´æ˜</div>
            è‡ªåŠ¨ç”ŸæˆCampaignæ‰§è¡ŒæŠ¥å‘Šï¼ŒåŒ…å«KOLè¡¨ç°ã€é£é™©è¯„ä¼°ã€è´Ÿé¢è¯„è®ºæ±‡æ€»ç­‰å†…å®¹ã€‚<br>
            å¯å¯¼å‡ºCSV/JSONæ ¼å¼ï¼Œæˆ–ç”ŸæˆWordæ–‡æ¡£æŠ¥å‘Šï¼ˆéœ€è¦å®‰è£…docxç›¸å…³ä¾èµ–ï¼‰ã€‚
        </div>
        """, unsafe_allow_html=True)
        
        # Generate report data
        report_data = generate_campaign_report_data(
            campaign_name,
            kol_analysis["kol_results"],
            kol_analysis["brand_name"]
        )
        
        # Display summary
        st.markdown("### ğŸ“Š Campaignæ‰§è¡Œæ‘˜è¦")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å‚ä¸KOLæ•°", report_data["kol_count"])
            st.metric("æ€»è¯„è®ºæ•°", report_data["total_comments"])
        
        with col2:
            st.metric("å¹³å‡æ­£é¢ç‡", f"{report_data['avg_positive_pct']:.1%}")
            st.metric("å¹³å‡è´Ÿé¢ç‡", f"{report_data['avg_negative_pct']:.1%}")
        
        with col3:
            st.metric("ä¸¥é‡é£é™©", report_data["risk_summary"]["critical"], delta_color="inverse")
            st.metric("é«˜é£é™©", report_data["risk_summary"]["high"], delta_color="inverse")
        
        st.markdown("---")
        
        # Top negative keywords
        if report_data["negative_keywords"]:
            st.markdown("### âš ï¸ ä¸»è¦è´Ÿé¢å…³é”®è¯")
            
            df_neg_kw = pd.DataFrame(report_data["negative_keywords"])
            st.dataframe(
                df_neg_kw[["keyword", "mentions", "category", "sentiment_score"]].head(10),
                use_container_width=True,
                hide_index=True
            )
        
        st.markdown("---")
        
        # Export options
        st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥å‘Š")
        
        col_dl1, col_dl2, col_dl3 = st.columns(3)
        
        # Prepare export data
        kol_summary_data = []
        for r in report_data["kol_results"]:
            kol_summary_data.append({
                "KOL": r["kol_name"],
                "è¯„è®ºæ•°": r["total_comments"],
                "æ­£é¢ç‡": f"{r['sentiment']['positive_pct']:.1%}",
                "è´Ÿé¢ç‡": f"{r['sentiment']['negative_pct']:.1%}",
                "é£é™©ç­‰çº§": r["risk"]["label"],
                "è´Ÿé¢è¯„è®ºæ•°": len(r["negative_comments"])
            })
        
        df_kol_summary = pd.DataFrame(kol_summary_data)
        
        with col_dl1:
            st.download_button(
                label="ğŸ“¥ KOLæ±‡æ€»CSV",
                data=df_kol_summary.to_csv(index=False).encode('utf-8-sig'),
                file_name=f"{campaign_name}_KOLæ±‡æ€»_{date.today()}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col_dl2:
            json_export = json.dumps(report_data, ensure_ascii=False, indent=2, default=str)
            st.download_button(
                label="ğŸ“¥ å®Œæ•´æŠ¥å‘ŠJSON",
                data=json_export.encode('utf-8'),
                file_name=f"{campaign_name}_å®Œæ•´æŠ¥å‘Š_{date.today()}.json",
                mime="application/json",
                use_container_width=True
            )
        
        with col_dl3:
            st.info("Wordæ–‡æ¡£ç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­")
        
        # Preview
        with st.expander("ğŸ“Š KOLæ±‡æ€»é¢„è§ˆ"):
            st.dataframe(df_kol_summary, use_container_width=True, hide_index=True)

else:
    with tab_report:
        st.markdown("## ğŸ“„ æŠ¥å‘Šå¯¼å‡º")
        
        if not st.session_state.analysis_results:
            st.info("ğŸ‘ˆ è¯·å…ˆåœ¨'åˆ†æçœ‹æ¿'è¿è¡Œåˆ†æ")
            st.stop()
        
        results = st.session_state.analysis_results
        primary_data = results["primary"]
        
        st.markdown("""
        <div class="explanation-box">
            <div class="explanation-title">ğŸ“– å¯¼å‡ºè¯´æ˜</div>
            æä¾›CSVå’ŒJSONæ ¼å¼å¯¼å‡ºï¼Œä¾¿äºåç»­åˆ†ææˆ–æ±‡æŠ¥ä½¿ç”¨ã€‚
        </div>
        """, unsafe_allow_html=True)
        
        keywords_df = pd.DataFrame(primary_data["keywords"])
        
        col_dl1, col_dl2 = st.columns(2)
        
        with col_dl1:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å…³é”®è¯CSV",
                data=keywords_df.to_csv(index=False).encode('utf-8-sig'),
                file_name=f"{primary_brand}_å…³é”®è¯_{date.today()}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col_dl2:
            json_export = json.dumps(results, ensure_ascii=False, indent=2, default=str)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´JSON",
                data=json_export.encode('utf-8'),
                file_name=f"{primary_brand}_åˆ†æ_{date.today()}.json",
                mime="application/json",
                use_container_width=True
            )

# ============================================================
# FOOTER
# ============================================================

st.markdown("---")

col_footer1, col_footer2, col_footer3 = st.columns(3)

with col_footer1:
    st.markdown("**ğŸ¯ æ ¸å¿ƒåŠŸèƒ½**")
    st.markdown("""
    - ç²¾å‡†å…³é”®è¯æå–
    - æ™ºèƒ½æƒ…æ„Ÿåˆ†æ
    - KOLç›‘æµ‹è¿½è¸ª
    - é£é™©è¯„ä¼°é¢„è­¦
    - CampaignæŠ¥å‘Š
    """)

with col_footer2:
    st.markdown("**ğŸ“Š åˆ†æç»´åº¦**")
    st.markdown("""
    - äº§å“ä½“éªŒ
    - æ€§ä»·æ¯”
    - åŒ…è£…è®¾è®¡
    - å”®åæœåŠ¡
    - çœŸä¼ªé—®é¢˜
    - ç‰©æµé…é€
    - ç«å“å¯¹æ¯”
    """)

with col_footer3:
    st.markdown("**ğŸ’¡ ä½¿ç”¨å»ºè®®**")
    st.markdown("""
    - æ¯ä¸ªKOL 20+è¯„è®º
    - æ¯å¤©æ›´æ–°ç›‘æµ‹
    - å…³æ³¨é«˜é£é™©KOL
    - åŠæ—¶å¤„ç†è´Ÿé¢
    """)

st.markdown("---")
st.caption("**Ultimate Brand Intelligence Platform** | KOL Monitoring Â· Risk Assessment Â· Campaign Tracking")
